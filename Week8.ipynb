{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 - Frozen Lake\n",
    "## Name: Rakshit Ramachandra Ayachit\n",
    "## Registration No.: 210968045\n",
    "## Batch: B1\n",
    "## Section: DSE-A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KvGIxp4eyALi"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C8HXEZGtyIQh"
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1',is_slippery=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate_state_value calculates the value of each possible action from the given current state\n",
    "based on the transition probabilities, rewards, and the value of the next states.\n",
    "It uses the Bellman equation to compute the action values, considering the discount factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QAoTteifyI2c"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_state_value(env, current_state, value_matrix, discount_factor):\n",
    "\n",
    "    num_actions = env.action_space.n\n",
    "    action_values = np.zeros(shape=num_actions)\n",
    "    for action in range(num_actions):\n",
    "        for transition_prob, next_state, reward, done in env.env.P[current_state][action]:\n",
    "            action_values[action] += transition_prob * (reward + discount_factor * value_matrix[next_state])\n",
    "    return action_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate_policy evaluates a given policy by iteratively estimating the state values\n",
    "until they converge or until the maximum number of iterations is reached.\n",
    "It updates the state values using the Bellman expectation equation.\n",
    "The convergence is determined by the change in state values being below a threshold.\n",
    "It returns the estimated state values for the given policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EheuMWhxyJd0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_policy(policy_matrix, environment, discount_factor=1.0, convergence_threshold=1e-9, max_iterations=1000):\n",
    "    num_states = environment.observation_space.n\n",
    "    evaluation_iterations = 1\n",
    "    state_values = np.zeros(shape=num_states)\n",
    "\n",
    "    for iteration in range(int(max_iterations)):\n",
    "        delta = 0\n",
    "        for current_state in range(num_states):\n",
    "            new_state_value = 0\n",
    "            for action, action_probability in enumerate(policy_matrix[current_state]):\n",
    "                for state_probability, next_state, reward, done in environment.P[current_state][action]:\n",
    "                    new_state_value += action_probability * state_probability * (reward + discount_factor * state_values[next_state])\n",
    "            delta = max(delta, np.abs(state_values[current_state] - new_state_value))\n",
    "            state_values[current_state] = new_state_value\n",
    "\n",
    "        evaluation_iterations += 1\n",
    "\n",
    "        if delta < convergence_threshold:\n",
    "            print(f'Policy evaluation terminated after {evaluation_iterations} iterations.\\n')\n",
    "            return state_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "policy_iteration_algorithm implements the policy iteration algorithm to find an optimal policy\n",
    "for a given environment. It iteratively evaluates and improves the policy until convergence.\n",
    "It starts with a random policy and repeatedly evaluates it using the policy evaluation function,\n",
    "and then improves the policy by selecting the best action for each state based on the current value function.\n",
    "If the policy becomes stable, the algorithm terminates\n",
    "and returns the optimal policy and the corresponding value function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IryDdEYmDs8Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "def policy_iteration_algorithm(environment, discount_factor=1.0, max_iterations=1000):\n",
    "    num_states = environment.observation_space.n\n",
    "    num_actions = environment.action_space.n\n",
    "    policy_matrix = np.ones(shape=[num_states, num_actions]) / num_actions\n",
    "    evaluated_policies_count = 1\n",
    "\n",
    "    for iteration in range(int(max_iterations)):\n",
    "        stable_policy = False\n",
    "        value_function = evaluate_policy(policy_matrix, environment, discount_factor)\n",
    "\n",
    "        for current_state in range(num_states):\n",
    "            current_action = np.argmax(policy_matrix[current_state])\n",
    "            action_values = calculate_state_value(environment, current_state, value_function, discount_factor)\n",
    "            best_action = np.argmax(action_values)\n",
    "\n",
    "            if current_action != best_action:\n",
    "                stable_policy = True\n",
    "\n",
    "            policy_matrix[current_state] = np.eye(num_actions)[best_action]\n",
    "\n",
    "        evaluated_policies_count += 1\n",
    "\n",
    "        if stable_policy:\n",
    "            print(f'Found a stable policy after {evaluated_policies_count:,} evaluations.\\n')\n",
    "            return policy_matrix, value_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_iteration_algorithm implements the value iteration algorithm to find an optimal policy\n",
    "for a given environment. It iteratively updates the state values until they converge\n",
    "or until the maximum number of iterations is reached.\n",
    "It then constructs the optimal policy based on the converged state values.\n",
    "The convergence is determined by the change in state values being below a threshold.\n",
    "It returns the optimal policy matrix and the converged state values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "v2-KjjYmyKSM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def value_iteration_algorithm(environment, discount_factor=1e-1, convergence_threshold=1e-9, max_iterations=1e4):\n",
    "    state_values = np.zeros(environment.observation_space.n)\n",
    "\n",
    "    for iteration in range(int(max_iterations)):\n",
    "        delta = 0\n",
    "\n",
    "        for current_state in range(environment.observation_space.n):\n",
    "            action_values = calculate_state_value(environment, current_state, state_values, discount_factor)\n",
    "            best_action_value = np.max(action_values)\n",
    "            delta = max(delta, np.abs(state_values[current_state] - best_action_value))\n",
    "            state_values[current_state] = best_action_value\n",
    "\n",
    "        if delta < convergence_threshold:\n",
    "            print(f'\\nValue iteration converged at iteration #{iteration+1:,}')\n",
    "            break\n",
    "\n",
    "    policy_matrix = np.zeros(shape=[environment.observation_space.n, environment.action_space.n])\n",
    "\n",
    "    for current_state in range(environment.observation_space.n):\n",
    "        action_values = calculate_state_value(environment, current_state, state_values, discount_factor)\n",
    "        best_action = np.argmax(action_values)\n",
    "        policy_matrix[current_state, best_action] = 1.0\n",
    "\n",
    "    return policy_matrix, state_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play_episodes_and_evaluate plays multiple episodes of the game according to a given policy matrix\n",
    "and evaluates the performance of the policy.\n",
    "It returns the total number of wins, total rewards, average reward per episode,\n",
    "and average number of actions taken per episode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HA0k2Qh8yK7R"
   },
   "outputs": [],
   "source": [
    "\n",
    "def play_episodes_and_evaluate(env, num_episodes, policy_matrix, max_actions=100, render=False):\n",
    "\n",
    "    total_wins = 0\n",
    "    total_rewards, total_actions = 0, 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        current_state = env.reset()\n",
    "        episode_done, actions_taken = False, 0\n",
    "\n",
    "        while actions_taken < max_actions:\n",
    "            selected_action = np.argmax(policy_matrix[current_state])\n",
    "            next_state, reward, episode_done, _ = env.step(selected_action)\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            actions_taken += 1\n",
    "            total_rewards += reward\n",
    "            current_state = next_state\n",
    "\n",
    "            if episode_done:\n",
    "                total_wins += 1\n",
    "                break\n",
    "\n",
    "        total_actions += actions_taken\n",
    "\n",
    "    print(f'Total rewards: {total_rewards:,}\\tMax actions: {actions_taken:,}')\n",
    "\n",
    "    average_reward = total_rewards / num_episodes\n",
    "    average_actions = total_actions / num_episodes\n",
    "\n",
    "    print('')\n",
    "    return total_wins, total_rewards, average_reward, average_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent_and_evaluate runs and evaluates different iteration methods (Policy Iteration and Value Iteration)\n",
    "for finding an optimal policy in the given environment.\n",
    "It prints the final policy obtained using each method and then evaluates the performance of the policy\n",
    "by playing multiple episodes and computing metrics such as total rewards, number of wins, average reward,\n",
    "and average number of actions taken per episode. Finally, it returns a list containing total rewards\n",
    "obtained for each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oo2MuWYQFnAW"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_episodes = 1000\n",
    "\n",
    "def agent_and_evaluate(env):\n",
    "\n",
    "    total_rewards_list = []\n",
    "\n",
    "    action_mapping = {\n",
    "        0: '\\u2191',  # up\n",
    "        1: '\\u2192',  # right\n",
    "        2: '\\u2193',  # down\n",
    "        3: '\\u2190'   # left\n",
    "    }\n",
    "\n",
    "    iteration_methods = [\n",
    "        ('Policy Iteration', policy_iteration_algorithm),\n",
    "        ('Value Iteration', value_iteration_algorithm)\n",
    "    ]\n",
    "\n",
    "    for method_name, method_func in iteration_methods:\n",
    "        policy_matrix, value_function = method_func(env)\n",
    "\n",
    "        print(f'Final policy using {method_name}:')\n",
    "        print(' '.join([action_mapping[action] for action in np.argmax(policy_matrix, axis=1)]))\n",
    "\n",
    "        total_wins, total_rewards, avg_reward, avg_actions = play_episodes_and_evaluate(env, num_episodes, policy_matrix)\n",
    "        total_rewards_list.append(total_rewards)\n",
    "\n",
    "        print(f'Number of wins = {total_wins:,}')\n",
    "        print(f'Average reward = {avg_reward:.2f}')\n",
    "        print(f'Average actions = {avg_actions:.2f}')\n",
    "\n",
    "    return total_rewards_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2UG0B9OGdjA",
    "outputId": "8eff5873-bad4-461d-bc8e-88b0fe5c1283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy evaluation terminated after 66 iterations.\n",
      "\n",
      "Found a stable policy after 2 evaluations.\n",
      "\n",
      "Final policy using Policy Iteration:\n",
      "↑ ← ↑ ← ↑ ↑ ↑ ↑ ← → ↑ ↑ ↑ ↓ → ↑\n",
      "Total rewards: 736.0\tMax actions: 21\n",
      "\n",
      "Number of wins = 1,000\n",
      "Average reward = 0.74\n",
      "Average actions = 42.53\n",
      "\n",
      "Value iteration converged at iteration #8\n",
      "Final policy using Value Iteration:\n",
      "→ ← ↓ ← ↑ ↑ ↑ ↑ ← → ↑ ↑ ↑ ↓ → ↑\n",
      "Total rewards: 425.0\tMax actions: 18\n",
      "\n",
      "Number of wins = 1,000\n",
      "Average reward = 0.42\n",
      "Average actions = 26.61\n"
     ]
    }
   ],
   "source": [
    "rewards = agent_and_evaluate(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: for Policy evaluation \n",
    "- Policy evaluation terminated after 66 iterations, meaning the value iteration process converged after evaluating policies.\n",
    "- A stable policy was found after 2 evaluations, indicating that the policy iteration algorithm converged quickly.\n",
    "- The final policy obtained from policy iteration is displayed as a sequence of actions for each state.\n",
    "- The total rewards accumulated over all episodes are 736.0, with a maximum of 21 actions taken in a single episode.\n",
    "- Out of 1,000 episodes, the agent won all of them, achieving the maximum possible success rate.\n",
    "- The average reward per episode is 0.74, indicating a high success rate.\n",
    "- The average number of actions per episode is 42.53, which is relatively high due to the nature of the environment.\n",
    "\n",
    "Observation: for Value iteration\n",
    "- Value iteration converged at iteration #8, indicating that the value iteration process converged quickly.\n",
    "- The final policy obtained from value iteration is displayed as a sequence of actions for each state.\n",
    "- The total rewards accumulated over all episodes are 425.0, with a maximum of 18 actions taken in a single episode.\n",
    "- Out of 1,000 episodes, the agent won all of them, achieving the maximum possible success rate.\n",
    "- The average reward per episode is 0.42, indicating a high success rate.\n",
    "- The average number of actions per episode is 26.61, which is relatively low compared to the policy iteration results.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize_policy defines a function to visualize policies obtained from policy iteration and value iteration.\n",
    "It converts the policy matrices into arrows representing actions (up, right, down, left) for each state.\n",
    "The arrows are displayed on a grid, where each cell corresponds to a state in the environment.\n",
    "The function then plots these arrows to visualize the policies graphically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy evaluation terminated after 66 iterations.\n",
      "\n",
      "Found a stable policy after 2 evaluations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value iteration converged at iteration #8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_policy(policy_matrix, title):\n",
    "    action_mapping = {\n",
    "        0: '\\u2191',  # up\n",
    "        1: '\\u2192',  # right\n",
    "        2: '\\u2193',  # down\n",
    "        3: '\\u2190'   # left\n",
    "    }\n",
    "    \n",
    "    policy_arrows = [action_mapping[action] for action in np.argmax(policy_matrix, axis=1)]\n",
    "    policy_arrows = np.array(policy_arrows).reshape((int(np.sqrt(len(policy_arrows))), -1))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.zeros(policy_arrows.shape))\n",
    "    for i in range(policy_arrows.shape[0]):\n",
    "        for j in range(policy_arrows.shape[1]):\n",
    "            plt.text(j, i, policy_arrows[i, j], ha='center', va='center', fontsize=20)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "policy_matrix_policy_iteration, _ = policy_iteration_algorithm(env)\n",
    "visualize_policy(policy_matrix_policy_iteration, \"Policy Iteration Policy\")\n",
    "\n",
    "policy_matrix_value_iteration, _ = value_iteration_algorithm(env)\n",
    "visualize_policy(policy_matrix_value_iteration, \"Value Iteration Policy\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
